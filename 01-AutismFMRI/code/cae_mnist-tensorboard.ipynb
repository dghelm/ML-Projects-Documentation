{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "Packages loaded\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "%matplotlib inline \n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "trainimgs   = mnist.train.images\n",
    "trainlabels = mnist.train.labels\n",
    "testimgs    = mnist.test.images\n",
    "testlabels  = mnist.test.labels\n",
    "ntrain      = trainimgs.shape[0]\n",
    "ntest       = testimgs.shape[0]\n",
    "dim         = trainimgs.shape[1]\n",
    "nout        = trainlabels.shape[1]\n",
    "print (\"Packages loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n1 = 16\n",
    "n2 = 32\n",
    "n3 = 64\n",
    "ksize = 5\n",
    "weights = {\n",
    "    'ce1': tf.Variable(tf.random_normal([ksize, ksize, 1, n1],  stddev=0.1)),\n",
    "    'ce2': tf.Variable(tf.random_normal([ksize, ksize, n1, n2], stddev=0.1)),\n",
    "    'ce3': tf.Variable(tf.random_normal([ksize, ksize, n2, n3], stddev=0.1)),\n",
    "    'cd3': tf.Variable(tf.random_normal([ksize, ksize, n2, n3], stddev=0.1)),\n",
    "    'cd2': tf.Variable(tf.random_normal([ksize, ksize, n1, n2], stddev=0.1)),\n",
    "    'cd1': tf.Variable(tf.random_normal([ksize, ksize, 1, n1],  stddev=0.1))\n",
    "}\n",
    "biases = {\n",
    "    'be1': tf.Variable(tf.random_normal([n1], stddev=0.1)),\n",
    "    'be2': tf.Variable(tf.random_normal([n2], stddev=0.1)),\n",
    "    'be3': tf.Variable(tf.random_normal([n3], stddev=0.1)),\n",
    "    'bd3': tf.Variable(tf.random_normal([n2], stddev=0.1)),\n",
    "    'bd2': tf.Variable(tf.random_normal([n1], stddev=0.1)),\n",
    "    'bd1': tf.Variable(tf.random_normal([1],  stddev=0.1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network ready\n"
     ]
    }
   ],
   "source": [
    "def cae(_X, _W, _b, _keepprob):\n",
    "    _input_r = tf.reshape(_X, shape=[-1, 28, 28, 1])\n",
    "    # Encoder\n",
    "    _ce1 = tf.nn.sigmoid(tf.add(tf.nn.conv2d(_input_r, _W['ce1']\n",
    "        , strides=[1, 2, 2, 1], padding='SAME'), _b['be1']))\n",
    "    _ce1 = tf.nn.dropout(_ce1, _keepprob)\n",
    "    _ce2 = tf.nn.sigmoid(tf.add(tf.nn.conv2d(_ce1, _W['ce2']\n",
    "        , strides=[1, 2, 2, 1], padding='SAME'), _b['be2'])) \n",
    "    _ce2 = tf.nn.dropout(_ce2, _keepprob)\n",
    "    _ce3 = tf.nn.sigmoid(tf.add(tf.nn.conv2d(_ce2, _W['ce3']\n",
    "        , strides=[1, 2, 2, 1], padding='SAME'), _b['be3'])) \n",
    "    _ce3 = tf.nn.dropout(_ce3, _keepprob)\n",
    "    # Decoder\n",
    "    _cd3 = tf.nn.sigmoid(tf.add(tf.nn.conv2d_transpose(_ce3, _W['cd3']\n",
    "        , tf.pack([tf.shape(_X)[0], 7, 7, n2]), strides=[1, 2, 2, 1]\n",
    "        , padding='SAME'), _b['bd3'])) \n",
    "    _cd3 = tf.nn.dropout(_cd3, _keepprob)\n",
    "    _cd2 = tf.nn.sigmoid(tf.add(tf.nn.conv2d_transpose(_cd3, _W['cd2']\n",
    "        , tf.pack([tf.shape(_X)[0], 14, 14, n1]), strides=[1, 2, 2, 1]\n",
    "        , padding='SAME') , _b['bd2'])) \n",
    "    _cd2 = tf.nn.dropout(_cd2, _keepprob)\n",
    "    _cd1 = tf.nn.sigmoid(tf.add(tf.nn.conv2d_transpose(_cd2, _W['cd1']\n",
    "        , tf.pack([tf.shape(_X)[0], 28, 28, 1]), strides=[1, 2, 2, 1]\n",
    "        , padding='SAME'), _b['bd1'])) \n",
    "    _cd1 = tf.nn.dropout(_cd1, _keepprob)\n",
    "    _out = _cd1\n",
    "    return {'input_r': _input_r, 'ce1': _ce1, 'ce2': _ce2, 'ce3': _ce3\n",
    "        , 'cd3': _cd3, 'cd2': _cd2, 'cd1': _cd1\n",
    "        , 'layers': (_input_r, _ce1, _ce2, _ce3, _cd3, _cd2, _cd1)\n",
    "        , 'out': _out}\n",
    "print (\"Network ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions ready\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, dim], name='x-input')\n",
    "y = tf.placeholder(tf.float32, [None, dim], name='y-input')\n",
    "keepprob = tf.placeholder(tf.float32)\n",
    "pred = cae(x, weights, biases, keepprob)['out']\n",
    "with tf.name_scope('cost'):\n",
    "    cost = tf.reduce_sum(tf.square(cae(x, weights, biases, keepprob)['out'] \n",
    "            - tf.reshape(y, shape=[-1, 28, 28, 1])))\n",
    "\n",
    "learning_rate = 0.001\n",
    "optm = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "init = tf.initialize_all_variables()\n",
    "print (\"Functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = mnist.train.next_batch(2)\n",
    "type(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strart training..\n",
      "[00/05] cost: 9101.4756\n",
      "[01/05] cost: 3578.6924\n",
      "[02/05] cost: 2552.5181\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cf2df29d923d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m#trainbatch.shape[0], 784)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         sess.run(optm, feed_dict={x: trainbatch\n\u001b[0;32m---> 18\u001b[0;31m                                   , y: trainbatch, keepprob: 0.7})\n\u001b[0m\u001b[1;32m     19\u001b[0m     print (\"[%02d/%02d] cost: %.4f\" % (epoch_i, n_epochs\n\u001b[1;32m     20\u001b[0m         , sess.run(cost, feed_dict={x: trainbatch\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "merged = tf.merge_all_summaries()\n",
    "summary_writer = tf.train.SummaryWriter('logs/cae_mnist', sess.graph)\n",
    "sess.run(init)\n",
    "# mean_img = np.mean(mnist.train.images, axis=0)\n",
    "mean_img = np.zeros((784))\n",
    "# Fit all training data\n",
    "batch_size = 128\n",
    "n_epochs   = 5\n",
    "print(\"Strart training..\")\n",
    "for epoch_i in range(n_epochs):\n",
    "    for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "        batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "        trainbatch = np.array([img - mean_img for img in batch_xs])\n",
    "        #trainbatch_noisy = trainbatch + 0.3*np.random.randn(\n",
    "            #trainbatch.shape[0], 784)\n",
    "        sess.run(optm, feed_dict={x: trainbatch\n",
    "                                  , y: trainbatch, keepprob: 0.7})\n",
    "    print (\"[%02d/%02d] cost: %.4f\" % (epoch_i, n_epochs\n",
    "        , sess.run(cost, feed_dict={x: trainbatch\n",
    "                                    , y: trainbatch, keepprob: 1.})))\n",
    "#    if (epoch_i % 1) == 0:\n",
    "#         n_examples = 5\n",
    "#         test_xs, _ = mnist.test.next_batch(n_examples)\n",
    "#         test_xs_noisy = test_xs + 0.3*np.random.randn(\n",
    "#             test_xs.shape[0], 784)\n",
    "#         recon = sess.run(pred, feed_dict={x: test_xs_noisy, keepprob: 1.})\n",
    "#         fig, axs = plt.subplots(2, n_examples, figsize=(15, 4))\n",
    "#         for example_i in range(n_examples):\n",
    "#             axs[0][example_i].matshow(np.reshape(\n",
    "#                 test_xs_noisy[example_i, :], (28, 28))\n",
    "#                 , cmap=plt.get_cmap('gray'))\n",
    "#             axs[1][example_i].matshow(np.reshape(\n",
    "#                 np.reshape(recon[example_i, ...], (784,))\n",
    "#                 + mean_img, (28, 28)), cmap=plt.get_cmap('gray'))\n",
    "#         plt.show()\n",
    "print(\"Training done. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRINT SHAPE OF THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of layer 1 is (1, 28, 28, 1)\n",
      "Shape of layer 2 is (1, 4, 4, 64)\n",
      "Shape of layer 3 is (1, 7, 7, 32)\n",
      "Shape of layer 4 is (1, 4, 4, 64)\n",
      "Shape of layer 5 is (1, 7, 7, 32)\n",
      "Shape of layer 6 is (1, 14, 14, 16)\n",
      "Shape of layer 7 is (1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "test_xs, _ = mnist.test.next_batch(1)\n",
    "test_xs_norm = np.array([img - mean_img for img in test_xs])\n",
    "recon = sess.run(pred, feed_dict={x: test_xs_norm, keepprob: 1.})\n",
    "layers = sess.run(cae(x, weights, biases, keepprob)['layers']\n",
    "                  , feed_dict={x: test_xs_norm, keepprob: 1.})\n",
    "for i in range(len(layers)):\n",
    "    currl = layers[i]\n",
    "    print ((\"Shape of layer %d is %s\") % (i+1, currl.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLOSE SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session closed.\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "print (\"Session closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}